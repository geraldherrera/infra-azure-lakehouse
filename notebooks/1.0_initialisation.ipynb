{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0c7d175-a4c0-4119-b5f0-7f12b60ae95c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Détection et sélection du catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2b279b3-63a9-4508-b147-f06125326a86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalogs = [row.catalog for row in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "unity_catalogs = [c for c in catalogs if c != \"hive_metastore\"]\n",
    "\n",
    "if len(unity_catalogs) == 1:\n",
    "    default_catalog = unity_catalogs[0]\n",
    "else:\n",
    "    # Choisir celui qui commence par 'dbw_' si plusieurs catalogs sont présents\n",
    "    default_catalog = next((c for c in unity_catalogs if c.startswith(\"dbw_\")), \"hive_metastore\")\n",
    "\n",
    "# Création d'un widget pour sélectionner dynamiquement le catalog\n",
    "dbutils.widgets.text(\"my_catalog\", default_catalog, \"Catalog détecté\")\n",
    "catalog = dbutils.widgets.get(\"my_catalog\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57d0f61c-c582-47b7-a706-e06165775150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Définition des noms de schémas utilisés pour le projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4af36334-ebbc-47b1-ba1b-fae8da2ae31c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_schema = \"bronze\"\n",
    "silver_schema = \"silver\"\n",
    "gold_schema = \"gold\"\n",
    "logs_schema = \"logs\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95d69f1e-c40d-4c6c-b5d5-16cfb10873e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Fonction pour créer un schéma si inexistant dans le catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31fab8da-0aad-4d29-baff-ef0f814767b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_schema_if_not_exists(schema_name):\n",
    "    spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema_name}\")\n",
    "    print(f\"Schéma {catalog}.{schema_name} prêt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c7f0899-6242-4210-87ea-aa57e974ddbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Création des schémas Bronze, Silver, Gold et Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d16724-1454-430c-8989-cf1137e4c069",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_schema_if_not_exists(bronze_schema)\n",
    "create_schema_if_not_exists(silver_schema)\n",
    "create_schema_if_not_exists(gold_schema)\n",
    "create_schema_if_not_exists(logs_schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae08d04-168d-4725-a245-22336ba5b501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Fonction générique pour créer une table de log si elle n'existe pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41b6de6d-8bbe-4a1c-9247-13964f8305ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_log_table_if_needed(table_name, schema):\n",
    "    full_table_name = f\"{catalog}.{logs_schema}.{table_name}\"\n",
    "    if not spark._jsparkSession.catalog().tableExists(full_table_name):\n",
    "        empty_df = spark.createDataFrame([], schema)\n",
    "        empty_df.write.format(\"delta\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .saveAsTable(full_table_name)\n",
    "        print(f\"Table {full_table_name} créée.\")\n",
    "    else:\n",
    "        print(f\"Table {full_table_name} déjà existante.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5839bdb6-a186-49b5-8a5f-9b7118aedadc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Schémas de logs utilisés pour chaque couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c35083f9-8319-4982-900c-92e1a2e39e69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType\n",
    "\n",
    "bronze_log_schema = StructType([\n",
    "    StructField(\"table_name\", StringType(), False),\n",
    "    StructField(\"timestamp\", TimestampType(), False),\n",
    "    StructField(\"status\", StringType(), False),\n",
    "    StructField(\"message\", StringType(), True)\n",
    "])\n",
    "\n",
    "silver_log_schema = StructType([\n",
    "    StructField(\"table_name\", StringType(), False),\n",
    "    StructField(\"timestamp\", TimestampType(), False),\n",
    "    StructField(\"status\", StringType(), False),\n",
    "    StructField(\"rows_inserted\", IntegerType(), True),\n",
    "    StructField(\"message\", StringType(), True)\n",
    "])\n",
    "\n",
    "gold_log_schema = StructType([\n",
    "    StructField(\"table_name\", StringType(), False),\n",
    "    StructField(\"timestamp\", TimestampType(), False),\n",
    "    StructField(\"status\", StringType(), False),\n",
    "    StructField(\"rows_inserted\", IntegerType(), True),\n",
    "    StructField(\"message\", StringType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "865fa551-88f6-4e9e-937f-bc2dd4758c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Création des tables de log pour Bronze, Silver et Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398fd442-2723-44f3-9408-5a96b7f5b797",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_log_table_if_needed(\"bronze_processing_log\", bronze_log_schema)\n",
    "create_log_table_if_needed(\"silver_processing_log\", silver_log_schema)\n",
    "create_log_table_if_needed(\"gold_processing_log\", gold_log_schema)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7212480681197945,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1.0 Initialisation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
